{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 05\n",
    "\n",
    "Name:  Carlos Contreras\n",
    "UID: U63425893\n",
    "\n",
    "### Topics\n",
    "\n",
    "- Cost Functions\n",
    "- Kmeans\n",
    "\n",
    "### Cost Function\n",
    "\n",
    "Solving Data Science problems often starts by defining a metric with which to evaluate solutions were you able to find some. This metric is called a cost function. Data Science then backtracks and tries to find a process / algorithm to find solutions that can optimize for that cost function.\n",
    "\n",
    "For example suppose you are asked to cluster three points A, B, C into two non-empty clusters. If someone gave you the solution `{A, B}, {C}`, how would you evaluate that this is a good solution?\n",
    "\n",
    "Notice that because the clusters need to be non-empty and all points must be assigned to a cluster, it must be that two of the three points will be together in one cluster and the third will be alone in the other cluster.\n",
    "\n",
    "In the above solution, if A and B are closer than A and C, and B and C, then this is a good solution. The smaller the distance between the two points in the same cluster (here A and B), the better the solution. So we can define our cost function to be that distance (between A and B here)!\n",
    "\n",
    "The algorithm / process would involve clustering together the two closest points and put the third in its own cluster. This process optimizes for that cost function because no other pair of points could have a lower distance (although it could equal it)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K means\n",
    "\n",
    "a) (1-dimensional clustering) Walk through Lloyd's algorithm step by step on the following dataset:\n",
    "\n",
    "`[0, .5, 1.5, 2, 6, 6.5, 7]` (note: each of these are 1-dimensional data points)\n",
    "\n",
    "Given the initial centroids:\n",
    "\n",
    "`[0, 2]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Points close to 0: 0, 0.5\n",
    "\n",
    "Points close to 2: 1.5, 2, 6, 6.5, 7\n",
    "\n",
    "average of clusters 1st round : \n",
    "\n",
    "close to 0: 0.25\n",
    "\n",
    "close to 2: 4.6\n",
    "\n",
    "second round of clustering:\n",
    "\n",
    "close to 0.25: 0, 0.5, 1.5, 2\n",
    "\n",
    "closer to 4.6: 6, 6.5, 7 \n",
    "\n",
    "Average of clusters in second round:\n",
    "\n",
    "close to 0.25: 1\n",
    "\n",
    "close to 4.6: 6.5\n",
    "\n",
    "Final Clusters\n",
    "\n",
    "Cluster with mean 1: 0, 0.5, 1.5, 2\n",
    "\n",
    "Cluster with mean 6.5: 6, 6.5, 7\n",
    "\n",
    "No change. therefore we are done by this point!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Describe in plain english what the cost function for k means is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is essentially a metric to determine how good a set of clusters is. the smalller the cost, the better. \n",
    "\n",
    "For each cluster, calculate the distance between the point and the cluster mean and square it to account for potential negative values. sum of all of these values to get the cost for an individual cluster. add the cost for all clusters to the cost function for the entire graph given K clusters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) For the same number of clusters K, why could there be very different solutions to the K means algorithm on a given dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of how we choose our centers. For example, if we have two clusters and place two random centers, such that only one point is closest to one center and all other points are closest to the other center then we will have two different clusters from one where we initially put two centers close to each other and both had multiple points near them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Does Lloyd's Algorithm always converge? Why / why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes. it will always converge. The algorithm cant get stuck in a cycle because this would require a clustering with a cost lower than itself. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Follow along in class the implementation of Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image as im\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets as datasets\n",
    "\n",
    "\n",
    "centers = [[0, 0], [2, 2], [-3, 2], [2, -4]]\n",
    "X, _ = datasets.make_blobs(n_samples=300, centers=centers, cluster_std=1, random_state=0)\n",
    "\n",
    "class KMeans():\n",
    "\n",
    "    def __init__(self, data, k):\n",
    "        self.data = data\n",
    "        self.k = k\n",
    "        self.assignment = [-1 for _ in range(len(data))]\n",
    "        self.snaps = []\n",
    "    \n",
    "    \n",
    "    def snap(self, centers):\n",
    "        \"\"\"\n",
    "        Essentially takes a snap picture of the points and creates a tempfile\n",
    "        \"\"\"\n",
    "        TEMPFILE = \"temp.png\"\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.scatter(X[:, 0], X[:, 1], c=self.assignment)\n",
    "        ax.scatter(centers[:,0], centers[:, 1], c='r')\n",
    "        fig.savefig(TEMPFILE)\n",
    "        plt.close()\n",
    "        self.snaps.append(im.fromarray(np.asarray(im.open(TEMPFILE))))\n",
    "\n",
    "    def is_unassigned(self, i):\n",
    "        ''' \n",
    "        checks if a data spot is unassigned. since we create with a defult value of -1, we just\n",
    "        need to check for  a -1 to know it is unassigned. \n",
    "        '''\n",
    "        return self.assignment[i] == -1 \n",
    "    \n",
    "\n",
    "    def unassigned_all(self):\n",
    "        \"\"\" \n",
    "        Unassigns values by converting all values in assignment back to -1\n",
    "        \"\"\"\n",
    "        self.assignment = [-1 for _ in range(len(self.data))]\n",
    "\n",
    "    def initialize(self): \n",
    "        ''' \n",
    "        Creates a list of lists where each list represents the coordiantes of a point we use as a center\n",
    "        '''\n",
    "        return self.data[np.random.choice(range(len(self.data)), size = self.k)]\n",
    "    \n",
    "    def assign(self,centers):\n",
    "        ''' \n",
    "        Assigns points in self.data to the closest center in centers.\n",
    "        modifies the self.assignment list to match points to a center \n",
    "        '''\n",
    "        # for each element of our data\n",
    "        for i in range(len(self.data)):\n",
    "\n",
    "            # change the assignment at that position to 0. this means the data point i is currently associated with center 0. \n",
    "            self.assignment[i] = 0 \n",
    "\n",
    "            #calculate the distance between our data point and the first center  \n",
    "            temp_dist = self.dist(self.data[i], centers[0])\n",
    "\n",
    "            # compare distances of a point to the centers to determine which center a point is closest to \n",
    "            for j in range(1,len(centers)):\n",
    "                new_dist = self.dist(self.data[i], centers[j])\n",
    "                # if a point is closer to another center than the current center it is assigned to, we should reassing the center it is associated to and change the current lowest center\n",
    "                # for the other comparisons. \n",
    "                if new_dist < temp_dist:\n",
    "                    self.assignment[i] = j\n",
    "                    temp_dist = new_dist\n",
    " \n",
    "    def dist(self,x, y):\n",
    "        return sum((x-y)**2) ** (1/2)\n",
    "    \n",
    "    def are_centers_diff(self, c1,c2):\n",
    "        ''' \n",
    "        Checks if two lists of centers are the same by comparing elements returns True if they are different\n",
    "        '''\n",
    "        for i in range(len(c1)):\n",
    "            if c1[i] not in c2:\n",
    "                return True\n",
    "        return False \n",
    "\n",
    "\n",
    "    def calculate_new_centers(self):\n",
    "        # We create an empty list to store our new centers\n",
    "        centers =  []\n",
    "        # We want to calculate calculate k new center, so we use a for loop\n",
    "        for j in range(self.k):\n",
    "            cluster_j = self.data[\n",
    "                np.array([i for i in range(len(self.data)) if self.assignment[i] == j])\n",
    "            ]\n",
    " \n",
    "            centers.append(np.mean(cluster_j,axis=0))\n",
    "        \n",
    "        return np.array(centers)\n",
    "        \n",
    "    def lloyds(self):\n",
    "\n",
    "        # first step is initializing the centers and taking a snap of the current chart \n",
    "        centers = self.initialize()\n",
    "        self.snaps.append(self.snap(centers))\n",
    "\n",
    "        # then we assign points to those centers  based on how close they are\n",
    "        self.assign(centers)\n",
    "        # Then calcualte the new means (new centers)\n",
    "        new_centers = self.calculate_new_centers()\n",
    "        \n",
    "\n",
    "        # repeat the process until centers dont change\n",
    "        while self.are_centers_diff(centers, new_centers):\n",
    "            centers = new_centers\n",
    "            self.unassigned_all()\n",
    "            self.assign(centers)\n",
    "            self.snap(centers)\n",
    "            new_centers = self.calculate_new_centers()\n",
    "        return\n",
    "            \n",
    "\n",
    "kmeans = KMeans(X, 6)\n",
    "kmeans.lloyds()\n",
    "images = kmeans.snaps\n",
    "\n",
    "\n",
    "images[0].save(\n",
    "    'kmeans.gif',\n",
    "    optimize=False,\n",
    "    save_all=True,\n",
    "    append_images=images[1:],\n",
    "    loop=0,\n",
    "    duration=500\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "76ca05dc3ea24b2e3b98cdb7774adfbb40773424bf5109b477fd793f623715af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
